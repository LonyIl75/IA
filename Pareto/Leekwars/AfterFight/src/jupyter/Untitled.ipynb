{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e00668a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "import json \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Leek:\n",
    "    path_data = \"D:\\\\Master\\\\S2\\\\TER\\\\GitLabTER\\\\leek-wars-generator-Lks-v3\\\\data\"\n",
    "    def __init__(self,dataOutcomeLeek):\n",
    "        self.stats = dict()\n",
    "        outcomeKeys = list(dataOutcomeLeek.keys())\n",
    "        for enumFile in [enumFile for enumFile in os.listdir(Leek.path_data) if enumFile.startswith('enum')]:\n",
    "            content = os.path.join(Leek.path_data,enumFile)\n",
    "            f = open(content, \"r\")\n",
    "            data=json.loads(f.read())\n",
    "            filename = os.path.splitext(enumFile[len('enum'):])[0]\n",
    "            self.stats.update({filename:[dict() for x in range(max(data[\"enumIndex\"]))]})\n",
    "            for i in range (len(data[\"enumIndex\"])):\n",
    "                enumName=data[\"enumName\"][i].lower()\n",
    "                if(enumName in outcomeKeys):\n",
    "                    self.stats[filename][data[\"enumIndex\"][i]].update({enumName:dataOutcomeLeek[enumName]})\n",
    "                \n",
    "\n",
    "def getLeekStats(filename_outcome_fight):          \n",
    "    f = open(filename_outcome_fight)\n",
    "    dataOutcome = json.load(f)\n",
    "    dataOutcome=json.loads(dataOutcome)[\"fight\"][\"leeks\"]\n",
    "    leeks = []\n",
    "    for idx_leek in range(len(dataOutcome)):\n",
    "        leek_file = Leek(dataOutcome[idx_leek])\n",
    "        leeks.append(leek_file)\n",
    "    return leeks\n",
    "\n",
    "\n",
    "\n",
    "#convertie un df string en dictionnaire dont la clef est titre de la colonne str_col_id et la valeur la serie de valeur de la colonne\n",
    "def toSeries(df,lst_dct, str_col_id,filter_val=\"[0]\"):\n",
    "    grp = df[[str_col_id, \"ID_ENTITY\",\"ID_TURN\"]].query(str_col_id+\"!=\"+filter_val).groupby(\"ID_ENTITY\")[str_col_id,\"ID_TURN\"]\n",
    "    \n",
    "    for key, values in grp:\n",
    "        tmp_grp = grp.get_group(key)\n",
    "        lst_tmp = [0 for i in range(tmp_grp[tmp_grp.columns[0]].size)]\n",
    "        for id_row , val_row in  tmp_grp.iterrows() :\n",
    "            lst_tmp[val_row[\"ID_TURN\"]]=ast.literal_eval(val_row[str_col_id])\n",
    "        if (not key in lst_dct):\n",
    "            lst_dct.update({key:dict()})\n",
    "\n",
    "        lst_dct[key].update({str_col_id:lst_tmp})\n",
    "        \n",
    "    return lst_dct\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "def getEvolutionStats(df , lst_statNegStat =[[\"1700\",\"LIFE\",\"\" ,\"LOST_LIFE\"]]):\n",
    "\n",
    "    lst_evolutionStat = []\n",
    "    #liste de dictionnaire ayant pour clef les titres dans lst_statNegStat \n",
    "    dct=dict()\n",
    "    for lst in lst_statNegStat:\n",
    "        for str_col_id in lst[1:]:\n",
    "            if( bool(str_col_id)):\n",
    "                dct=toSeries(df,dct,str_col_id)\n",
    "        lst_evolutionStat.append(dct)\n",
    "\n",
    "    lst_life = dict()\n",
    "    #pour tous les dictionnaires de lst_evolutionStat calcule la somme des valeurs associé à chaque colonne \n",
    "    for dct in lst_evolutionStat:\n",
    "        for k in dct.keys(): \n",
    "            lst_life.update({k:{}})\n",
    "            for z in range(len(lst_statNegStat)) :\n",
    "                lst = lst_statNegStat[z]\n",
    "                lst_life[k].update({lst[1]:[int(lst[0])]})\n",
    "                lst=lst[1:]\n",
    "                sum_lst = lst_life[k][lst[0]]\n",
    "                for i in range(1,len(dct[k][lst[0]])+1):\n",
    "                    sum_lst.append(sum_lst[i-1])\n",
    "                    neg=1\n",
    "                    for str_col_id in lst:\n",
    "                            if( not(bool(str_col_id))):\n",
    "                                neg= -1\n",
    "                                continue\n",
    "                            dct_val = dct[k][str_col_id]\n",
    "                            sum_lst[i] += neg*sum(dct_val[i-1])\n",
    "    return lst_life\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#df.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "\n",
    "def recap_fight(df ,  filter_lst_val = [\"MOVE_TO\"] , id_startWith ='ID' , seq_endWith='s' ,  n_key = [\"fight_gen_idLeek\",\"dimension\", \"seq_lens\",\"mean\",\"std\",\"min\",\"max\"]):\n",
    "\n",
    "\n",
    "    id_cols = [col for col in df.columns if col.startswith(id_startWith)]\n",
    "    feat_cols = [col for col in df.columns if not(col in filter_lst_val  ) and not(id_startWith in col)  and not col.lower().endswith(seq_endWith) ] \n",
    "\n",
    "    #print(feat_cols)\n",
    "    df2 = df.copy()[id_cols+feat_cols]\n",
    "\n",
    "\n",
    "    for i in range(len(df2[feat_cols[0]])):\n",
    "        for c in feat_cols :\n",
    "            df2[c][i] = pd.to_numeric(ast.literal_eval(df2[c][i]))\n",
    "\n",
    "\n",
    "\n",
    "    to_column_map = df2.set_index(id_cols)\n",
    "\n",
    "    grouped = df2.groupby(id_cols[:-1])\n",
    "\n",
    "    dict_gen = dict()\n",
    "\n",
    "    obj_json_stats = dict. fromkeys(n_key)\n",
    "\n",
    "    #.append(dictionary, ignore_index=True)\n",
    "    n_df = pd.DataFrame(columns=n_key)\n",
    "    for name, group in grouped:\n",
    "\n",
    "\n",
    "        dict_val = dict()\n",
    "        for f in feat_cols :\n",
    "            dict_val.update({f:group[f].apply(pd.Series).stack().values})\n",
    "\n",
    "        treshold = 0\n",
    "        stats = dict()\n",
    "\n",
    "        for f in dict_val.keys() :\n",
    "            tmp_obj = obj_json_stats.copy()\n",
    "            seq_lens = [0]\n",
    "            for e in dict_val[f]:\n",
    "                if(e > treshold):\n",
    "                    seq_lens[-1]+=(1/len(dict_val[f]))\n",
    "                elif(seq_lens[-1]>0):\n",
    "                    seq_lens.append(0)\n",
    "\n",
    "            tmp_obj[\"seq_lens\"] = sum(seq_lens)/len(seq_lens)\n",
    "            tmp_obj[\"mean\"] = df2[f].mean()[0]\n",
    "            tmp_obj[\"std\"] = df2[f].std()\n",
    "            tmp_obj[\"min\"] = df2[f].min()[0]\n",
    "            tmp_obj[\"max\"] = df2[f].max()[0]\n",
    "            \n",
    "            tmp_obj[\"dimension\"]=f\n",
    "\n",
    "            tmp_obj[\"fight_gen_idLeek\"]=name\n",
    "            n_df = n_df.append(tmp_obj, ignore_index=True)\n",
    "\n",
    "    return n_df \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def m_flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "\n",
    "def getlst_statNegStat( leek,str_lst = [\"LIFE\"]):\n",
    "    lst_statNegStat =[]\n",
    "    for str_col_id in str_lst:\n",
    "        kl = leek.stats \n",
    "        t_l = str_col_id.lower()\n",
    "        for k, e in kl.items():\n",
    "            dct= e[0]\n",
    "            if(t_l in  dct):\n",
    "                    t_l2=t_l.upper()\n",
    "                    lst_statNegStat.append([str(dct[t_l]),t_l2,\"\",\"LOST_\"+t_l2])\n",
    "                    break\n",
    "    return lst_statNegStat\n",
    "\n",
    "\n",
    "def getlstValAndLstIdx( df, filename_test_json ):\n",
    "    leeks=getLeekStats( filename_test_json )\n",
    "    lst_statNegStat = getlst_statNegStat( leeks[0])  \n",
    "    lst_life = getEvolutionStats(df,lst_statNegStat)\n",
    "    return lst_life , lst_statNegStat\n",
    "\n",
    "\n",
    "\n",
    "def mergeNegStat (lst_life ,cols ,id_=\"ID_LEEK\") :\n",
    "\n",
    "    df2  = pd.DataFrame(columns=[id_]+cols  )\n",
    "\n",
    "    for k in lst_life.keys():\n",
    "        tmp_obj=dict({id_:k})\n",
    "        tmp_obj.update(lst_life[k])\n",
    "        df2=pd.concat([df2,pd.DataFrame([tmp_obj])], ignore_index=True)\n",
    "\n",
    "    df3= pd.DataFrame(columns=[id_]+cols  )\n",
    "    for col in cols : \n",
    "        t= df2.set_index([id_])[col].apply(pd.Series).stack()\n",
    "        df4=t.to_frame()\n",
    "        df4.rename(columns={0:col},inplace=True)\n",
    "        if(col == cols[0]):\n",
    "            df3=df4\n",
    "        else:\n",
    "            df3=df3.join(df4)\n",
    "        \n",
    "    return df3\n",
    "\n",
    "def getColsFromLstStatNegStat(lst_statNegStat):\n",
    "    return m_flatten([ list(filter(lambda x: x , e[1:2] )) for e in lst_statNegStat ])\n",
    "\n",
    "\n",
    "def printAxis(df5,_id=\"ID_LEEK\"):\n",
    "    key_leek = list(set([e[0] for e in df5.index.values]))\n",
    "    for i,k in enumerate(key_leek):\n",
    "        df_o = df5.iloc[df5.index.get_level_values(_id) == k].reset_index(drop=True)\n",
    "        if(i==0):\n",
    "            ax = df_o.plot()\n",
    "        else:\n",
    "            df_o.plot(ax=ax)\n",
    "        ax.legend(key_leek)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "\n",
    "def getCumulStat(df,filename_test_json):\n",
    "    lst_life , lst_statNegStat  = getlstValAndLstIdx(  df,filename_test_json )\n",
    "    cols = getColsFromLstStatNegStat(lst_statNegStat)\n",
    "    df5  = mergeNegStat (lst_life ,cols )\n",
    "    return df5\n",
    "\n",
    "\n",
    "def convert_XY_toCoord(XY):\n",
    "    coef_x = XY//18\n",
    "    coord_x = XY%18\n",
    "    \n",
    "    sign_x =  0 if coord_x < coef_x else -18\n",
    "    print(sign_x)\n",
    "    coef_y = XY//17\n",
    "    coord_y= XY%17\n",
    "    sign_y = 0 if coord_y < coef_y  else -18\n",
    "    print(sign_y)\n",
    "    \n",
    "    tmp_x = None\n",
    "    return (coord_y+sign_y,-(coord_x+sign_x))\n",
    "\n",
    "\n",
    "\n",
    "def getCoords(df):\n",
    "    dtr = dict()\n",
    "    dtr = toSeries(df,dtr, \"MAPS\")\n",
    "    coords = dict()\n",
    "    for k in dtr.keys() :\n",
    "        dtr_map = dtr[k][\"MAPS\"]\n",
    "        coords.update({k:dict()})\n",
    "        for i in range(len(dtr[k][\"MAPS\"])):\n",
    "                if( len(dtr_map[i]) > 1 ):\n",
    "                    coords[k].update({i:[convert_XY_toCoord(t_coord) for t_coord in dtr_map[i]]})\n",
    "    return coords\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getMapPlot(df,coords):\n",
    "    dict_tuple = dict()\n",
    "\n",
    "    for k1 in coords.keys(): #pour chaque leek \n",
    "        dict_tuple.update({k1:[[],[]]})\n",
    "        coords_1 = coords[k1]\n",
    "        for k2 in coords_1.keys():#pour chaque tour \n",
    "            for coord in coords_1[k2]: # pour chaque position \n",
    "                for i , e in enumerate(coord): #pour chaque dimension de la position \n",
    "                    dict_tuple[k1][i].append(e)\n",
    "    return dict_tuple\n",
    "\n",
    "def dfFromCoordDict(dct, str_coord=[\"x\",\"y\"]):\n",
    "    df_final = pd.DataFrame()\n",
    "    print(dct)\n",
    "    for k,v in dct.items():\n",
    "        df = pd.DataFrame(columns=[\"ID_LEEK\"]+str_coord)\n",
    "        for i , l in enumerate(v) : \n",
    "            df[str_coord[i]] = l\n",
    "        df[\"ID_LEEK\"] = k\n",
    "        df_final = pd.concat([df_final,df])\n",
    "    return df_final.reset_index()\n",
    "\n",
    "\n",
    "def plot2DMap(df,colors = ['red', 'green', 'blue', 'yellow', 'black', 'purple', 'orange', 'pink', 'brown', 'grey', 'olive', 'cyan']):\n",
    "    grp = df.groupby([\"ID_LEEK\"])\n",
    "    fig, ax1 = plt.subplots(figsize=(17,17))\n",
    "    for i, k in enumerate(grp.groups.keys()):\n",
    "        df_o = grp.get_group(k)\n",
    "        ax1.scatter(df_o[\"x\"], df_o[\"y\"], c=colors[i % len(colors)], alpha=0.5, edgecolors='none', s=30)\n",
    "    return ax1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import shutil\n",
    "\n",
    "class SaveStat :\n",
    "    \n",
    "    \n",
    "        \n",
    "    def __init__(self,_filename_test_csv,_filename_test_json,outcome_filename):\n",
    "        if(os.path.isfile(outcome_filename)):\n",
    "            outcome_filename= Path(outcome_filename).stem\n",
    "\n",
    "      \n",
    "\n",
    "        self.filename = os.path.splitext(outcome_filename)[0]\n",
    "        self.path_out = os.path.join(\"D:\\\\Master\\\\S2\\\\TER\\\\GitLabTER\\\\AfterFight\\\\data\",self.filename).replace(\"\\\\\",\"/\")\n",
    "        self.position_map_save = os.path.join(self.path_out,\"mapPosition\").replace(\"\\\\\",\"/\")\n",
    "        self.stat_save = os.path.join(self.path_out,\"stats\").replace(\"\\\\\",\"/\")\n",
    "        self.recap_save =  os.path.join(self.path_out,\"recaps\").replace(\"\\\\\",\"/\")\n",
    "        \n",
    "        self.filename_test_csv=_filename_test_csv\n",
    "        self.filename_test_json = _filename_test_json\n",
    "\n",
    "\n",
    "        self.init_dir()\n",
    "        \n",
    "        self.filename_evolutionCurve = \"evolutionCurve.csv\"\n",
    "        self.filename_recap = \"recap.csv\"\n",
    "        self.filename_position = \"position.csv\"\n",
    "        \n",
    "\n",
    "\n",
    "        self.init_dataframe()\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def init_dir (self):\n",
    "        isExist = os.path.exists(self.path_out)\n",
    "\n",
    "        isExist = os.path.exists(self.path_out)\n",
    "\n",
    "        if isExist:\n",
    "            shutil.rmtree(self.path_out)\n",
    "\n",
    "        os.mkdir(self.path_out)    \n",
    "        os.mkdir(self.position_map_save)\n",
    "        os.mkdir(self.stat_save)\n",
    " \n",
    "    \n",
    "\n",
    "\n",
    "    def init_dataframe(self):\n",
    "            self.df = pd.read_csv(self.filename_test_csv, sep=\";\")      \n",
    "            self.df.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "            #display(self.df)\n",
    "            \n",
    "            \n",
    "    def saveMap(self):\n",
    "        coords = getCoords(self.df)\n",
    "        dict_tuple = getMapPlot(self.df,coords)\n",
    "        df78 = dfFromCoordDict(dict_tuple)\n",
    "        print('ii')\n",
    "        display(df78)\n",
    "        ax1 = plot2DMap(df78)\n",
    "        ax1.figure.savefig( os.path.join(self.position_map_save , self.filename+\".png\"))\n",
    "        df78.to_csv( self.recap_save+self.filename_position, mode='a', sep=\";\")\n",
    "\n",
    "\n",
    "    def saveStat(self):\n",
    "        df5 = getCumulStat(self.df , self.filename_test_json)\n",
    "        ax= printAxis(df5)\n",
    "        df5.to_csv(self.recap_save+self.filename_evolutionCurve, mode='a', sep=\";\")\n",
    "        ax.figure.savefig( os.path.join(self.stat_save , self.filename +\".png\"))\n",
    "\n",
    "\n",
    "\n",
    "    def saveRecap(self):\n",
    "        n_df = recap_fight(self.df)\n",
    "        n_df.to_csv(self.recap_save+self.filename_recap, mode='a', sep=\";\")\n",
    "\n",
    "\n",
    "    def writeFiles(self):\n",
    "        self.saveMap()\n",
    "        self.saveStat()\n",
    "        self.saveRecap()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _fucn(outcome_filename ):\n",
    "\t\n",
    "\tfilename = os.path.splitext(outcome_filename)[0]\n",
    "\n",
    "\n",
    "\tpath_out = os.path.join(\"D:\\\\Master\\\\S2\\\\TER\\\\GitLabTER\\\\AfterFight\\\\data\",filename)\n",
    "\tfilename_test_csv = os.path.join(path_out,filename+\".csv\")\n",
    "\tfilename_test_json = os.path.join(\"D:\\\\Master\\\\S2\\\\TER\\\\GitLabTER\\\\AfterFight\\outcome\",filename+\".json\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\tSaveStat(filename_test_csv,filename_test_json,outcome_filename).writeFiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1aa502d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "outcome_filename_2 = \"150_489_12-62_1680156349326.json\"\n",
    "\n",
    "outcome_filename = \"145_487_12-62_1680155935861.json\"\n",
    "\n",
    "\n",
    "filename = os.path.splitext(outcome_filename)[0]\n",
    "\n",
    "\n",
    "path_out = os.path.join(\"..\",\"data\",filename).replace(\"\\\\\",\"/\")\n",
    "filename_test_csv = os.path.join(\"D:\\\\Master\\\\S2\\\\TER\\\\GitLabTER\\\\AfterFight\\\\data\",\"145_487_12-62_1680155935861.csv\").replace(\"\\\\\",\"/\")\n",
    "filename_test_json = os.path.join(\"D:\\\\Master\\\\S2\\\\TER\\\\GitLabTER\\\\AfterFight\\outcome\",outcome_filename).replace(\"\\\\\",\"/\")\n",
    "\n",
    "filename_test_csv2 = os.path.join(\"D:\\\\Master\\\\S2\\\\TER\\\\GitLabTER\\\\AfterFight\\\\data\",\"150_489_12-62_1680156349326.csv\").replace(\"\\\\\",\"/\")\n",
    "filename_test_json2 = os.path.join(\"D:\\\\Master\\\\S2\\\\TER\\\\GitLabTER\\\\AfterFight\\outcome\",outcome_filename_2).replace(\"\\\\\",\"/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85c9052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f211a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/145_487_12-62_1680118885684\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "print(path_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b045f128",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " def convert_XY_toCoord(XY):\n",
    "    coef_x = XY//18\n",
    "    coord_x = XY%18\n",
    "    sign_x =  0 if coord_x < coef_x else -18\n",
    "    coef_y = XY//17\n",
    "    coord_y= XY%17\n",
    "    sign_y = 0 if coord_y < coef_y  else -18\n",
    "    \n",
    "    tmp_x = None\n",
    "    return (coord_y+sign_y,-(coord_x+sign_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "52dad9e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, -14)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_XY_toCoord(428)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee35413",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SaveStat(filename_test_csv ,filename_test_json,outcome_filename).writeFiles())\n",
    "print(\"iii\")\n",
    "print(SaveStat(filename_test_csv2 ,filename_test_json2,outcome_filename_2).writeFiles())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6444cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import shutil\n",
    "from subprocess import Popen, PIPE\n",
    "import sys\n",
    "from threading import Thread, Lock\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import requests\n",
    "from math import ceil\n",
    "from uuid import getnode\n",
    "import socket \n",
    "import os \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np \n",
    "from pathlib import Path\n",
    "from filenameVerif import _emptyTuple,filename_isvalid,splitIds,getIdsPos,getGenPos,getFightPos\n",
    "from ReaderFilesEager import *\n",
    "import ast\n",
    "\n",
    "file_csv = \"D:\\Master\\S2\\TER\\GitLabTER\\te\\12-62_1681156232985.csv\"\n",
    "def groupTo_dct(group , str_col):\n",
    "    lst_2={}\n",
    "\n",
    "    \n",
    "    for e in group[str_col]:\n",
    "        print(e)\n",
    "        if(bool(e)):\n",
    "            if( not(isinstance(e[1] , int))):\n",
    "                    lst=[]\n",
    "                    for e3 in ast.literal_eval(e[1]).tolist():\n",
    "                        lst+=ast.literal_eval(e3)\n",
    "                    lst_2.update({e[0]:lst})\n",
    "    return lst_2\n",
    "\n",
    "\n",
    "\n",
    "df55 = pd.read_csv(file_csv,sep=\";\",encoding=\"utf-8\")\n",
    "group = df55.groupby([\"ID_ENTITY\"])\n",
    "print(group)\n",
    "lost_life  = group['LOST_LIFE'].sum().tolist()\n",
    "life =  [e for e in group[\"LIFE\"] ]\n",
    "dct_1 = groupTo_dct(group,\"LOST_LIFE\")\n",
    "dct_2 = groupTo_dct(group,\"LIFE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "04cddfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isInInterval ( e, interval ):\n",
    "    e = int(e)\n",
    "    return e >= interval[0] and e< interval[1] \n",
    "\n",
    "\n",
    "def reversedict( in_dict ):\n",
    "        res_dict = dict()\n",
    "        for k ,v in in_dict.items() :\n",
    "            res_dict.update({v : k})\n",
    "        return  res_dict\n",
    "\n",
    "def print_pyth(_str):\n",
    "    print(\"[PYTH]\" + str(_str))\n",
    "\n",
    "def isJsonFile( filename ):\n",
    "    return filename.endswith(\".json\")\n",
    "\n",
    "def errorMessage( _class : object, _method :str ,  _str: str  ):\n",
    "    print(\"[ERROR] \" + (\" from :\" + type(_class ) +\",\") if _class !=\"\"  else \"\" + (\"method :\" +_method +\",\") if _method !=\"\" else \"\" +   \" description : \" + _str)\n",
    "\n",
    "def errorMessage( _str: str ):\n",
    "    errorMessage( \"\" , \"\", _str)\n",
    "\n",
    "def errorMessage( _method :str, _str: str ):\n",
    "    errorMessage( \"\" , _method, _str)\n",
    "\n",
    "\n",
    "def errorMessagePyth( _str: str ):\n",
    "    print_pyth(errorMessage( _str ))\n",
    "\n",
    "def errorMessagePyth( _method:str , _str: str ):\n",
    "    print_pyth(errorMessage(_method , _str ))\n",
    "\n",
    "def errorMessagePyth( _class:str , _method:str , _str: str ):\n",
    "    print_pyth(errorMessage(_class , _method , _str ))\n",
    "\n",
    "\n",
    "def errorMessageFromClass(obj : object, _str: str ):\n",
    "    errorMessage( obj ,\"\", _str)\n",
    "\n",
    "def errorMessageFromClassPyth(obj:object , _str: str ):\n",
    "   print_pyth(errorMessage( obj , \"\" , _str ))\n",
    "\n",
    "\n",
    "def notFound():\n",
    "    return -1\n",
    "\n",
    "def notSetId():\n",
    "    return -1\n",
    "\n",
    "def badInsert():\n",
    "    return -1\n",
    "\n",
    "def outOfRange():\n",
    "    return -1\n",
    "\n",
    "def strColInCols(str_col:str , df ):\n",
    "    return str_col in df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "1759f5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "from myutil  import *\n",
    "import os \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "'''\n",
    "ReadActions :\n",
    "    - STATIC :\n",
    "        - MAP_SIZE : nombre de cases sur la map\n",
    "        - intervals_ends : fin des intervalles des types d'actions ( e.g Times : 100 ,  Buffs: 200 , ... )\n",
    "        - intervals_dict : dictionnaire inversé de intervals_dict ( e.g { {START_FIGHT: 0 ,...,USE_WEAPON: 16  , LOST_PT : 100 , ... , NOVA_VITALITY :  112 , ... }  }# le fichier filename_dfActions loader \n",
    "        - intervals_dictRev : dictionnaire des types d'actions ( e.g {0:START_FIGHT ,...,16: USE_WEAPON , ... } # le fichier filename_dfActions loader reversed\n",
    "        - filename_dfActions : nom du fichier json contenant les actions de chaque types d'actions ainsi que la taille des intervalles \n",
    "        - ex_idx : liste des index des membres du json  a exclure (e.g [0,2,3]<=> interval_size , Funs , Others )\n",
    "        - lst_col : liste des colonnes non calculer (directement accessible via l'outcome ) à stocker dans le dataframe\n",
    "        - id_col : liste des colonnes contenant les ids identifiants les lignes du dataframe\n",
    "        - deg_col : liste des colonnes contenant les degats infligés ou subis par les entités (parmis les colonnes décritent dans lst_col)\n",
    "        - audit_col : liste des types d'actions performer pendant le tour (e.g [0,0,1,2,1,1] <=> [df.cols[0] , df.cols[0], df.cols[1] , ...] <=> [Times , Times , Buffs , ...])\n",
    "\n",
    "    - NON STATIC :\n",
    "        - numGen : numéro de la génération\n",
    "        - numFight : numéro du combat\n",
    "        - beg_notCodeAct_col : index indiquant le début des colonnes qui ne sont pas des liste de codes d'actions\n",
    "        - entities_ids : les ids réelle des entités (telle que spécifié dans le scénario[\"entities\"][i][\"id\"] ) impliquées dans le fight du dataframe \n",
    "        - int_col_idx_in_lst_col : liste des index des colonnes contenant des ints dans lst_col \n",
    "\n",
    "'''\n",
    "class ReadActions :\n",
    "    MAP_SIZE = 612 \n",
    "    intervals_ends = dict()\n",
    "    intervals_dict = dict()\n",
    "    intervals_dictRev = dict()\n",
    "    filename_dfActions = os.path.join(\"..\",\"..\",\"leek-wars-generator-Lks-v3\",\"data\",\"df_Action.json\")\n",
    "    ex_idx = [0,2,3]\n",
    "    lst_col = ['LOST_LIFE','LIFE','MOVE_TO','WEAPON_DEG','CHIP_DEG','MAPS','WEAPON_ID','CHIP_ID']\n",
    "    id_col = ['ID_GEN','ID_FIGHT','ID_ENTITY','ID_TURN']\n",
    "    deg_col = ['LOST_LIFE','LIFE','WEAPON_DEG','CHIP_DEG']\n",
    "    audit_col = [\"ACTIONS\"]\n",
    "    \n",
    "    #maps = [ [0]*MAP_SIZE ,[0]*MAP_SIZE]\n",
    "    \n",
    "    def __init__(self,ids :list ,numGen :int , numFight:int ,path_atm :str ):\n",
    "        self.numGen = numGen\n",
    "        self. numFight = numFight\n",
    "        self.numTurn = 0\n",
    "        ReadActions.init_intervals(ReadActions.filename_dfActions)#,ReadActions.ex_idx)\n",
    "        self.nb_type = len(ReadActions.intervals_ends)\n",
    "        self.lst_col_code = [list(ReadActions.intervals_ends.keys())[i] for i in range(1,len(ReadActions.intervals_ends)) ] \n",
    "        self.df = pd.DataFrame(columns=self.lst_col_code+ReadActions.lst_col+ReadActions.id_col+ReadActions.audit_col)\n",
    "        self.beg_notCodeAct_col = len(self.df.columns) - len(ReadActions.lst_col)-len(ReadActions.id_col)-1\n",
    "        self.entities_ids = ids \n",
    "        self.setIntCol()\n",
    "        \n",
    "    def setDF(self,df2):\n",
    "        if(df2.columns == self.df.columns):\n",
    "            self.df = pd.concat([self.df , df2])\n",
    "            \n",
    "        \n",
    "    def setIntCol(self):\n",
    "        self.int_col_idx_in_lst_col = []\n",
    "        for i,d in enumerate(self.df.columns.tolist()) :\n",
    "            if d in ReadActions.deg_col :\n",
    "                self.int_col_idx_in_lst_col+=[i]\n",
    "        self.int_col_idx_in_lst_col.sort()\n",
    "\n",
    "\n",
    "    @property\n",
    "    def getNumGen(self):\n",
    "        return self.numGen\n",
    "    \n",
    "    @property\n",
    "    def getNumFight(self):\n",
    "        return self.numFight\n",
    "    \n",
    "    @property\n",
    "    def getNumTurn(self):\n",
    "        return self.numTurn\n",
    "    \n",
    "    @property\n",
    "    def getDF(self):\n",
    "        return self.df\n",
    "    \n",
    "    @property\n",
    "    def getEntitiesIds(self):\n",
    "        return self.entities_ids\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def emptyIntervalsEnd():\n",
    "            ReadActions.intervals_ends.update({'BEGIN':0})\n",
    "\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def init_intervals(filename_json_dfA :str ,ex_idx=[]):\n",
    "            \"\"\"\n",
    "            filename_json_dfA : fichier json contenant les actions de chaque types d'actions ainsi que la taille des intervalles\n",
    "            ex_idx : liste des index des membres du json  a exclure (e.g [0,2,3]<=> interval_size , Funs , Others )\n",
    "\n",
    "            Description : initialise les attributs intervals_dict , intervals_dictRev , intervals_ends de la classe ReadActions grâce au fichier json passer en paramètre\n",
    "            \"\"\"\n",
    "            if( isJsonFile( filename_json_dfA ) ):\n",
    "                ReadActions.emptyIntervalsEnd()\n",
    "                #Load json file\n",
    "                with open(filename_json_dfA, 'r') as f:\n",
    "                    df_actions_json = json.load(f)\n",
    "                interval_size = df_actions_json[\"interval_size\"]\n",
    "\n",
    "                #ignore interval_size from dictionnary\n",
    "                del df_actions_json[\"interval_size\"]\n",
    "\n",
    "                #ignore ex_idx from dictionnary\n",
    "                for to_ignore in ex_idx :\n",
    "                    del df_actions_json[to_ignore]\n",
    "\n",
    "                #extract info from dict and load it in class attributes \n",
    "\n",
    "                idx_keyOf_action = 0\n",
    "                idx_intcodeOf_action = 1\n",
    "                for i,group_of_actions in enumerate(df_actions_json.items())  :\n",
    "                    id_group,lst_actions=group_of_actions\n",
    "                    \n",
    "                    for action in lst_actions.items():\n",
    "                        ReadActions.intervals_dict.update({action[idx_keyOf_action]:action[idx_intcodeOf_action]})\n",
    "\n",
    "                    ReadActions.intervals_ends.update({id_group:(interval_size+1)*(i+1)})\n",
    "                ReadActions.intervals_dictRev = reversedict(ReadActions.intervals_dict)\n",
    "            else :\n",
    "                errorMessagePyth(\"file\"+filename_json_dfA+\" must be a json file\")\n",
    "        \n",
    "     \n",
    "    \n",
    "    @staticmethod\n",
    "    def whileToken(str_token : str , lst_actions :list ):\n",
    "        \"\"\"\n",
    "        str_token : le string correspondant au token a chercher dans lst_actions ( un token est exprimer sous la forme d'un int dans lst_actions)\n",
    "        lst_actions : liste d'actions  a parcourir   ( lst_action[i][0] == code_token ) \n",
    "\n",
    "        Description : parcours lst_actions jusqu'a ce que le token soit trouvé ou que la fin de la liste soit atteinte \n",
    "        Return : l'index de l'action token dans lst_actions tel que ( lst_action[index][0] == code_token )  ou -1 si le token n'a pas été trouvé\n",
    "        \"\"\"\n",
    "        for i in range(len(lst_actions)) :\n",
    "            action = lst_actions[i]\n",
    "            if(action[0] == ReadActions.intervals_dict.get(str_token)):\n",
    "                i+=1\n",
    "                return i\n",
    "        return notFound()\n",
    "    \n",
    "\n",
    "    @staticmethod        \n",
    "    def isEndFight(act_token: int):\n",
    "        return act_token == ReadActions.intervals_dict.get(\"END_FIGHT\")\n",
    "    \n",
    "    @staticmethod \n",
    "    def isBeginFight(act_token: int):\n",
    "        return act_token == ReadActions.intervals_dict.get(\"START_FIGHT\")\n",
    "    \n",
    "    @staticmethod \n",
    "    def isBeginTurn(act_token: int):\n",
    "        return act_token == ReadActions.intervals_dict.get(\"NEW_TURN\")\n",
    "    \n",
    "    @staticmethod \n",
    "    def isEndTurn(act_token: int):\n",
    "        return ReadActions.isEndFight(act_token) or ReadActions.isBeginTurn(act_token ) or act_token == ReadActions.intervals_dict.get(\"END_TURN\")\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def getDfLstTypeActions():\n",
    "        return list([[]])\n",
    "    \n",
    "    @staticmethod\n",
    "    def getDfLstAudit():\n",
    "        return list([[]])\n",
    "    \n",
    "    @staticmethod\n",
    "    def getDfLstInLstCol():\n",
    "        return [0]\n",
    "    \n",
    "    @staticmethod\n",
    "    def getDfLstNotInLstCol():\n",
    "        return []\n",
    "    \n",
    "\n",
    "    def getNewRow(self):\n",
    "        lst =[]\n",
    "\n",
    "        #-----------------Type Actions [Times,Buffs , ... ] -----------------\n",
    "        idx = 0 \n",
    "        idx_end = self.beg_notCodeAct_col \n",
    "        #Type of actions , e.g Times,Buffs,Funs,Effects , Others \n",
    "        for i in range (idx,idx_end):\n",
    "            lst.append(ReadActions.getDfLstTypeActions())\n",
    "\n",
    "        t=0\n",
    "        #----------------- Lst Col -----------------\n",
    "        idx = idx_end\n",
    "        idx_end +=len(ReadActions.lst_col)\n",
    "        for i in range (idx , idx_end):\n",
    "            if i in self.int_col_idx_in_lst_col[t:] :\n",
    "                lst.append(ReadActions.getDfLstInLstCol())\n",
    "                t+=1\n",
    "            #elif ReadActions.lst_col[i-idx] in [\"WEAPON_ID\",\"CHIP_ID\"]:\n",
    "            #    lst.append(notSetId())\n",
    "            else :\n",
    "                lst.append(ReadActions.getDfLstNotInLstCol())\n",
    "\n",
    "        #----------------- Not in Lst Col -----------------\n",
    "        idx = idx_end\n",
    "        idx_end += len(ReadActions.id_col)\n",
    "        for i in range (idx ,  idx_end):\n",
    "            lst.append(notSetId())\n",
    "\n",
    "        #----------------- Audit -----------------\n",
    "        idx = idx_end\n",
    "        idx_end += len(ReadActions.audit_col)\n",
    "        for i in range (idx,idx_end):\n",
    "            lst.append(ReadActions.getDfLstAudit())#actions\n",
    "\n",
    "\n",
    "\n",
    "        return lst\n",
    "    \n",
    "    def idxNextRow(self):\n",
    "        return self.getCurrentIDX()+1\n",
    "    \n",
    "    def addNewRow(self):\n",
    "        self.df.loc[self.idxNextRow()]=self.getNewRow()\n",
    "    \n",
    "        \n",
    "    def addNewTurn(self,idx_turn: int):\n",
    "        \"\"\"\n",
    "        idx_turn : index du tour a ajouter\n",
    "        Description : ajoute une nouvelle ligne et set sont indexe de tour à idx_turn\n",
    "        \"\"\"\n",
    "        self.addNewRow()\n",
    "        #self.numTurn = idx_turn\n",
    "        self.setColumn ('ID_TURN', idx_turn )\n",
    "        \n",
    "    def getCurrentIDX (self):\n",
    "        return len(self.df)-1\n",
    "\n",
    "    def setColumn ( self , str_col:str ,val):\n",
    "        \"\"\"\n",
    "        Description : set la colonne str_col de la ligne courante à val\n",
    "        \"\"\"\n",
    "        if ( strColInCols(str_col ,self.df)):\n",
    "            self.df.loc[self.getCurrentIDX(),str_col]= val \n",
    "    \n",
    "\n",
    "    def addToColumn(self,str_col:str,val,pos:int=0):\n",
    "        \"\"\"\n",
    "        val : valeur a ajouter a la liste de la colonne str_col de la ligne courante\n",
    "        pos : position de la valeur a ajouter dans la liste de la colonne str_col de la ligne courante (par defaut 0)\n",
    "\n",
    "        Description : ajoute une valeur a la liste de la colonne str_col de la ligne courante\n",
    "        \"\"\"\n",
    "        if (strColInCols(str_col ,self.df)):\n",
    "            lst=self.df.loc[self.getCurrentIDX(),str_col]\n",
    "\n",
    "            if( len(lst )< pos):\n",
    "                errorMessagePyth(self,\"addToColumn\" , \"index out of range\")\n",
    "\n",
    "            if( not(bool(lst)) or len(lst )== pos):\n",
    "                lst+=[0]\n",
    "            \n",
    "            lst[pos]+= val  \n",
    "\n",
    "        return pos \n",
    "            \n",
    "            \n",
    "    def addToColumnList(self,str_col:str,val,pos:int=0):\n",
    "        \"\"\"\n",
    "        Attention : on embedde la valeur dans une liste car la colonne str_col est de type liste \n",
    "        \"\"\"\n",
    "        if(len(self.df[str_col]) == 0  or not(isinstance(self.df[str_col][0],list))):\n",
    "            errorMessagePyth(self,\"addToColumnList\" , \"column \"+str_col+\" must be a list\")\n",
    "            return badInsert()\n",
    "        else :\n",
    "            return self.addToColumn(str_col , [val],pos) \n",
    "\n",
    "    def extendColum(self,str_col:str,val:list):\n",
    "        \"\"\"\n",
    "        Description : on ajoute une liste a la liste de la colonne str_col de la ligne courante\n",
    "        \"\"\"\n",
    "        if (strColInCols(str_col ,self.df)):\n",
    "            self.df.loc[self.getCurrentIDX(),str_col].extend(val)\n",
    "       \n",
    "\n",
    "    def addToAudit(self , idx:int , idx_of_actionType :int ,   act_token:int  ):\n",
    "        \"\"\"\n",
    "        Description : on ajoute l'index du type de l'action courante dans la colonne audit correspondante\n",
    "        \"\"\"\n",
    "        err_code=self.addToColumnList (  ReadActions.audit_col[idx],idx_of_actionType)\n",
    "        if(err_code == badInsert()):\n",
    "            errorMessagePyth(self, \"addToCategory\" , \"bad insert\")\n",
    "            \n",
    "    def addToGroupAction(self,idx_of_actionType:int , act_token:int):\n",
    "        err_code = self.addToColumnList (list(ReadActions.intervals_ends.keys())[idx_of_actionType],act_token)\n",
    "        if(err_code == badInsert()):\n",
    "            errorMessagePyth(self, \"addToCategory\" , \"bad insert\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def setIDs(self,entity_id:int):\n",
    "        \"\"\"\n",
    "        Description : set les colonnes IDs de la ligne courante sauf ID_TURN \n",
    "        \"\"\"\n",
    "        self.setColumn ('ID_GEN',self.numGen)\n",
    "        self.setColumn ('ID_FIGHT',self. numFight)\n",
    "        self.setColumn ('ID_ENTITY',self.getEntityID(entity_id))\n",
    "        #self.setColumn ('ID_TURN',self.idx_turn)\n",
    "        \n",
    "    def getEntityID(self ,entity_id:int ):\n",
    "        \"\"\"\n",
    "        Description : retourne l'ID de l'entité entity_id si elle existe sinon retourne outOfRange()\n",
    "        \"\"\"\n",
    "        if len(self.entities_ids) > entity_id :\n",
    "            return self.entities_ids[entity_id]\n",
    "        \n",
    "        else :\n",
    "            errorMessagePyth(self,\"getEntityID\" , \"index out of range\")\n",
    "            return outOfRange()\n",
    "        \n",
    "    @staticmethod\n",
    "    def getIdxCodeToken():\n",
    "        return 0\n",
    "    @staticmethod\n",
    "    def getIdxEntityToken():\n",
    "        return 1\n",
    "    \n",
    "    @staticmethod\n",
    "    def getCodeToken(_lst :list):\n",
    "        return _lst[ReadActions.getIdxCodeToken()]\n",
    "    @staticmethod\n",
    "    def getEntityToken(_lst :list):\n",
    "        return _lst[ReadActions.getIdxEntityToken()]\n",
    "    \n",
    "    def getTurn( self,lst_actions :list ,idx_turn :int ):\n",
    "        entity_id = -1 \n",
    "        \n",
    "        # continue jusqu'au token LEEK_TURN\n",
    "        nbActionRead=ReadActions.whileToken(\"LEEK_TURN\",lst_actions)\n",
    "\n",
    "        k = nbActionRead\n",
    "\n",
    "        if(k==notFound()):\n",
    "            return k , None \n",
    "        \n",
    "        act_token = ReadActions.getCodeToken(lst_actions[k])\n",
    "        entity_id =  ReadActions.getEntityToken(lst_actions[k-1])\n",
    "        \n",
    "        self.addNewTurn(idx_turn)\n",
    "        self.setIDs(entity_id)\n",
    "\n",
    "        #si le tour est vide : \n",
    "        if(self.isEndTurn(act_token)):\n",
    "            return k , entity_id \n",
    "        \n",
    "        idx=0\n",
    "        while k  < len(lst_actions):\n",
    "\n",
    "            act_token = ReadActions.getCodeToken(lst_actions[k])\n",
    "\n",
    "            #si le tour est fini : \n",
    "            if(self.isEndTurn(act_token) ):\n",
    "                return k , entity_id\n",
    "            \n",
    "\n",
    "            for i in range(1,len(ReadActions.intervals_ends)):\n",
    "                #idx_group_actions=i\n",
    "                interval = [list(ReadActions.intervals_ends.values())[i-1],list(ReadActions.intervals_ends.values())[i]]\n",
    "                if(act_token  in ReadActions.intervals_dictRev and isInInterval(act_token , interval )) :\n",
    "                    \n",
    "                    _id = ReadActions.getEntityToken(lst_actions[k])\n",
    "                    self.addToAudit(ReadActions.audit_col.index(\"ACTIONS\"),i,act_token)\n",
    "                    self.addToGroupAction(i , act_token)\n",
    "\n",
    "        \n",
    "\n",
    "                    if(list(ReadActions.intervals_ends.keys())[i] == \"Times\"):\n",
    "\n",
    "                        if(ReadActions.intervals_dictRev.get(act_token) == \"MOVE_TO\"):\n",
    "                            lst_mv = lst_actions[k][3]\n",
    "                            self.extendColum('MOVE_TO',[lst_mv[0],len(lst_mv),lst_mv[-1]])\n",
    "                            self.extendColum('MAPS',lst_mv)\n",
    "                            \n",
    "  \n",
    "                            \n",
    "                    elif(list(ReadActions.intervals_ends.keys())[i] == \"Buffs\"):\n",
    "                        if(ReadActions.intervals_dictRev.get(act_token) == 'HEAL'):\n",
    "                            self.addToColumn('LIFE',lst_actions[k][2])\n",
    "                        elif(ReadActions.intervals_dictRev.get(act_token) in ['LOST_LIFE','NOVA_DAMAGE','DAMAGE_RETURN','LIFE_DAMAGE','POISON_DAMAGE',' AFTEREFFECT']):\n",
    "                            self.addToColumn('LOST_LIFE',lst_actions[k][2])\n",
    "                    elif(list(ReadActions.intervals_ends.keys())[i] == \"Effects\"):\n",
    "                        if(ReadActions.intervals_dictRev.get(act_token) == 'ADD_WEAPON_EFFECT'):\n",
    "                            self.addToColumn('WEAPON_DEG',lst_actions[k][5])\n",
    "                            self.extendColum('WEAPON_ID',[_id])\n",
    "                        elif(ReadActions.intervals_dictRev.get(act_token) == 'ADD_CHIP_EFFECT'):\n",
    "                                self.addToColumn('CHIP_DEG',lst_actions[k][5])\n",
    "                                self.extendColum('CHIP_ID',[_id])\n",
    "                                \n",
    "                    \n",
    "                    \n",
    "            k+=1\n",
    "            idx+=1\n",
    "        return k , entity_id\n",
    "\n",
    "                            \n",
    "                    \n",
    "    def getFight ( self,lst_actions:list ):\n",
    "        nbReads=ReadActions.whileToken(\"START_FIGHT\",lst_actions)\n",
    "\n",
    "        k=nbReads\n",
    "\n",
    "        idx_turn = 0 \n",
    "        while k < len(lst_actions):\n",
    "            act_token =ReadActions.getCodeToken(lst_actions[k])\n",
    "            if(self.isEndFight(act_token )):\n",
    "                return k \n",
    "            nbReads , ent_id = self.getTurn(lst_actions[k:],idx_turn)\n",
    "            if(nbReads==-1):\n",
    "                break\n",
    "            k+=(nbReads+1)\n",
    "            if(k < len(lst_actions)):\n",
    "                act_token =ReadActions.getCodeToken(lst_actions[k])\n",
    "                if(self.isBeginTurn(act_token)):\n",
    "                    idx_turn +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "aea037b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Master\\S2\\TER\\GitlabTER\\AfterFight\\src\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "c8824c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file =\"D:\\Master\\S2\\TER\\GitLabTER\\AfterFight\\outcome\\243_10_12-62_1681001459881.json\"\n",
    "rr = ReadActions([12,62],243,10,json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "18763c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"../outcome/243_10_12-62_1681001459881.json\", 'r') as f:\n",
    "    data = json.loads(json.load(f))\n",
    "    \n",
    "lst_actions = data[\"fight\"][\"actions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "b135aac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.getFight (lst_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "b8ccf04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Times</th>\n",
       "      <th>Buffs</th>\n",
       "      <th>Funs</th>\n",
       "      <th>Effects</th>\n",
       "      <th>Others</th>\n",
       "      <th>LOST_LIFE</th>\n",
       "      <th>LIFE</th>\n",
       "      <th>MOVE_TO</th>\n",
       "      <th>WEAPON_DEG</th>\n",
       "      <th>CHIP_DEG</th>\n",
       "      <th>MAPS</th>\n",
       "      <th>WEAPON_ID</th>\n",
       "      <th>CHIP_ID</th>\n",
       "      <th>ID_GEN</th>\n",
       "      <th>ID_FIGHT</th>\n",
       "      <th>ID_ENTITY</th>\n",
       "      <th>ID_TURN</th>\n",
       "      <th>ACTIONS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[12, 12, 10, 12, 12, 12, 12, 13]]</td>\n",
       "      <td>[[101, 103]]</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[302, 302, 302, 302, 302, 302, 302, 302, 302,...</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[68]</td>\n",
       "      <td>[43]</td>\n",
       "      <td>[486, 10, 499]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[173]</td>\n",
       "      <td>[486, 503, 520, 502, 484, 466, 483, 465, 482, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[14, 14, 96, 96, 19, 20, 20, 3, 21, 21]</td>\n",
       "      <td>243</td>\n",
       "      <td>10</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>[[1, 4, 4, 1, 4, 4, 1, 1, 4, 2, 1, 4, 4, 1, 4,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[12, 12, 10, 12, 12, 12, 12, 13]]</td>\n",
       "      <td>[[101, 103]]</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[302, 302, 302, 302, 302, 302, 302, 302, 302,...</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[186]</td>\n",
       "      <td>[43]</td>\n",
       "      <td>[581, 10, 463]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[173]</td>\n",
       "      <td>[581, 564, 547, 530, 513, 496, 514, 497, 480, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[14, 14, 96, 96, 19, 20, 20, 3, 21, 21]</td>\n",
       "      <td>243</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>[[1, 4, 4, 1, 4, 4, 1, 1, 4, 2, 1, 4, 4, 1, 4,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[16, 16, 14, 13, 12, 12, 10, 10, 12]]</td>\n",
       "      <td>[[101, 101, 103, 103, 101]]</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[301, 305, 301, 301, 305, 302, 305, 302, 302]]</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[62]</td>\n",
       "      <td>[22]</td>\n",
       "      <td>[482, 1, 482, 464, 2, 446]</td>\n",
       "      <td>[29]</td>\n",
       "      <td>[16]</td>\n",
       "      <td>[482, 464, 446]</td>\n",
       "      <td>[41, 41, 41]</td>\n",
       "      <td>[4, 97, 19]</td>\n",
       "      <td>243</td>\n",
       "      <td>10</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>[[1, 4, 2, 4, 4, 1, 4, 2, 2, 4, 1, 1, 1, 4, 2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[16, 16, 14, 13, 12, 12, 12]]</td>\n",
       "      <td>[[110, 101, 103, 101, 103, 103, 103]]</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[301, 305, 301, 301, 305, 305, 302, 302, 302]]</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[86]</td>\n",
       "      <td>[176]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[29]</td>\n",
       "      <td>[17]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[41, 41, 41]</td>\n",
       "      <td>[97, 4, 3]</td>\n",
       "      <td>243</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>[[2, 1, 4, 2, 2, 4, 4, 1, 4, 2, 2, 4, 1, 1, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[16, 16, 13, 12, 12, 12, 13, 10, 10, 10, 10, ...</td>\n",
       "      <td>[[110, 101, 101, 101, 101, 101, 101, 101, 101]]</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[303, 303, 303, 301, 301, 301, 301, 301, 301,...</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[19]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[428, 1, 428, 446, 1, 446, 428, 1, 428, 446, 1...</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[428, 446, 428, 446, 428, 446, 428, 446]</td>\n",
       "      <td>[38, 38, 38, 38, 38, 38]</td>\n",
       "      <td>[97, 2, 18]</td>\n",
       "      <td>243</td>\n",
       "      <td>10</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>[[2, 4, 4, 4, 1, 4, 2, 4, 2, 4, 2, 1, 4, 2, 4,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[16, 16, 13, 12, 12, 12, 13]]</td>\n",
       "      <td>[[110, 110, 101, 101, 101, 101, 101, 101, 101,...</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[303, 303, 303, 301, 301, 301, 301, 301, 301,...</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[38, 38, 38, 38, 38, 38]</td>\n",
       "      <td>[97, 2, 18]</td>\n",
       "      <td>243</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>[[2, 2, 4, 4, 4, 1, 4, 2, 4, 2, 4, 2, 1, 4, 2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[16, 16, 13, 12, 12, 12, 10, 10, 10, 10, 10, ...</td>\n",
       "      <td>[[110, 110, 101, 103, 101, 103, 103, 103]]</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[303, 303, 301, 301, 305, 302, 302, 302]]</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[220]</td>\n",
       "      <td>[114]</td>\n",
       "      <td>[428, 1, 428, 446, 1, 446, 428, 1, 428, 446, 1...</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[17]</td>\n",
       "      <td>[428, 446, 428, 446, 428, 446, 428, 446]</td>\n",
       "      <td>[45, 45]</td>\n",
       "      <td>[97, 4, 3]</td>\n",
       "      <td>243</td>\n",
       "      <td>10</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>[[2, 2, 4, 4, 1, 4, 2, 2, 1, 4, 2, 2, 1, 1, 4,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[16, 16, 14, 13, 12, 12, 12]]</td>\n",
       "      <td>[[110, 110, 110, 101, 103, 101, 103, 103, 103]]</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[303, 303, 301, 305, 301, 301, 305, 305, 302,...</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[517]</td>\n",
       "      <td>[249]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[29]</td>\n",
       "      <td>[17]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[41, 41, 41]</td>\n",
       "      <td>[97, 4, 3]</td>\n",
       "      <td>243</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>[[2, 2, 2, 4, 4, 1, 4, 2, 2, 4, 4, 1, 4, 2, 2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[16, 16, 13, 12, 12, 16, 10, 10, 10, 10, 10, ...</td>\n",
       "      <td>[[110, 110, 110, 101, 103, 101, 103, 101, 103,...</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[303, 301, 301, 301, 301, 301, 301, 305, 302,...</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[925]</td>\n",
       "      <td>[172]</td>\n",
       "      <td>[428, 1, 428, 446, 1, 446, 428, 1, 428, 446, 1...</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[14]</td>\n",
       "      <td>[428, 446, 428, 446, 428, 446, 428, 446]</td>\n",
       "      <td>[38, 38, 38, 38, 38, 38, 38, 38, 38]</td>\n",
       "      <td>[97, 2]</td>\n",
       "      <td>243</td>\n",
       "      <td>10</td>\n",
       "      <td>62</td>\n",
       "      <td>4</td>\n",
       "      <td>[[2, 2, 2, 4, 1, 4, 2, 2, 4, 2, 2, 4, 2, 2, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[16, 16, 13, 12, 12, 16]]</td>\n",
       "      <td>[[110, 110, 110, 101, 103, 101, 103, 101, 103,...</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[303, 303, 301, 301, 301, 301, 301, 301, 305,...</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[760]</td>\n",
       "      <td>[142]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[14]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[38, 38, 38, 38, 38, 38, 38, 38, 38]</td>\n",
       "      <td>[97, 2]</td>\n",
       "      <td>243</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>[[2, 2, 2, 4, 4, 1, 4, 2, 2, 4, 2, 2, 4, 2, 2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[16, 16, 13, 12, 12, 12, 10, 10, 10, 10, 10, ...</td>\n",
       "      <td>[[110, 110, 110, 101, 103, 101, 103, 101, 103,...</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[303, 301, 301, 301, 301, 301, 301, 305, 302,...</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[663]</td>\n",
       "      <td>[244]</td>\n",
       "      <td>[428, 1, 428, 446, 1, 446, 428, 1, 428, 446, 1...</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[16]</td>\n",
       "      <td>[428, 446, 428, 446, 428, 446, 428, 446]</td>\n",
       "      <td>[38, 38, 38, 38, 38, 38]</td>\n",
       "      <td>[97, 4, 2]</td>\n",
       "      <td>243</td>\n",
       "      <td>10</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>[[2, 2, 2, 4, 1, 4, 2, 2, 4, 2, 2, 4, 2, 2, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[16, 16, 13, 12, 12, 12]]</td>\n",
       "      <td>[[110, 110, 110, 101, 103, 101, 103, 101, 103,...</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[303, 301, 301, 301, 301, 301, 301, 305, 302,...</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[678]</td>\n",
       "      <td>[237]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[16]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[38, 38, 38, 38, 38, 38]</td>\n",
       "      <td>[97, 4, 2]</td>\n",
       "      <td>243</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>[[2, 2, 2, 4, 1, 4, 2, 2, 4, 2, 2, 4, 2, 2, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[16, 16, 5, 13, 12, 12, 12, 13, 10, 10, 10, 1...</td>\n",
       "      <td>[[110, 110, 110, 101, 103, 101, 103, 101, 103,...</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[303, 301, 301, 301, 301, 301, 303, 303, 303,...</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[476]</td>\n",
       "      <td>[121]</td>\n",
       "      <td>[428, 1, 428, 410, 1, 410, 392, 1, 392, 410, 1...</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[148]</td>\n",
       "      <td>[428, 410, 392, 410, 392, 410, 392, 410, 392, ...</td>\n",
       "      <td>[38, 38, 38, 38, 38]</td>\n",
       "      <td>[14, 14, 96, 96, 3]</td>\n",
       "      <td>243</td>\n",
       "      <td>10</td>\n",
       "      <td>62</td>\n",
       "      <td>6</td>\n",
       "      <td>[[2, 2, 2, 4, 1, 4, 2, 2, 4, 2, 2, 4, 2, 2, 1,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Times  \\\n",
       "0                  [[12, 12, 10, 12, 12, 12, 12, 13]]   \n",
       "1                  [[12, 12, 10, 12, 12, 12, 12, 13]]   \n",
       "2              [[16, 16, 14, 13, 12, 12, 10, 10, 12]]   \n",
       "3                      [[16, 16, 14, 13, 12, 12, 12]]   \n",
       "4   [[16, 16, 13, 12, 12, 12, 13, 10, 10, 10, 10, ...   \n",
       "5                      [[16, 16, 13, 12, 12, 12, 13]]   \n",
       "6   [[16, 16, 13, 12, 12, 12, 10, 10, 10, 10, 10, ...   \n",
       "7                      [[16, 16, 14, 13, 12, 12, 12]]   \n",
       "8   [[16, 16, 13, 12, 12, 16, 10, 10, 10, 10, 10, ...   \n",
       "9                          [[16, 16, 13, 12, 12, 16]]   \n",
       "10  [[16, 16, 13, 12, 12, 12, 10, 10, 10, 10, 10, ...   \n",
       "11                         [[16, 16, 13, 12, 12, 12]]   \n",
       "12  [[16, 16, 5, 13, 12, 12, 12, 13, 10, 10, 10, 1...   \n",
       "\n",
       "                                                Buffs  Funs  \\\n",
       "0                                        [[101, 103]]  [[]]   \n",
       "1                                        [[101, 103]]  [[]]   \n",
       "2                         [[101, 101, 103, 103, 101]]  [[]]   \n",
       "3               [[110, 101, 103, 101, 103, 103, 103]]  [[]]   \n",
       "4     [[110, 101, 101, 101, 101, 101, 101, 101, 101]]  [[]]   \n",
       "5   [[110, 110, 101, 101, 101, 101, 101, 101, 101,...  [[]]   \n",
       "6          [[110, 110, 101, 103, 101, 103, 103, 103]]  [[]]   \n",
       "7     [[110, 110, 110, 101, 103, 101, 103, 103, 103]]  [[]]   \n",
       "8   [[110, 110, 110, 101, 103, 101, 103, 101, 103,...  [[]]   \n",
       "9   [[110, 110, 110, 101, 103, 101, 103, 101, 103,...  [[]]   \n",
       "10  [[110, 110, 110, 101, 103, 101, 103, 101, 103,...  [[]]   \n",
       "11  [[110, 110, 110, 101, 103, 101, 103, 101, 103,...  [[]]   \n",
       "12  [[110, 110, 110, 101, 103, 101, 103, 101, 103,...  [[]]   \n",
       "\n",
       "                                              Effects Others LOST_LIFE   LIFE  \\\n",
       "0   [[302, 302, 302, 302, 302, 302, 302, 302, 302,...   [[]]      [68]   [43]   \n",
       "1   [[302, 302, 302, 302, 302, 302, 302, 302, 302,...   [[]]     [186]   [43]   \n",
       "2     [[301, 305, 301, 301, 305, 302, 305, 302, 302]]   [[]]      [62]   [22]   \n",
       "3     [[301, 305, 301, 301, 305, 305, 302, 302, 302]]   [[]]      [86]  [176]   \n",
       "4   [[303, 303, 303, 301, 301, 301, 301, 301, 301,...   [[]]      [19]    [0]   \n",
       "5   [[303, 303, 303, 301, 301, 301, 301, 301, 301,...   [[]]      [34]    [0]   \n",
       "6          [[303, 303, 301, 301, 305, 302, 302, 302]]   [[]]     [220]  [114]   \n",
       "7   [[303, 303, 301, 305, 301, 301, 305, 305, 302,...   [[]]     [517]  [249]   \n",
       "8   [[303, 301, 301, 301, 301, 301, 301, 305, 302,...   [[]]     [925]  [172]   \n",
       "9   [[303, 303, 301, 301, 301, 301, 301, 301, 305,...   [[]]     [760]  [142]   \n",
       "10  [[303, 301, 301, 301, 301, 301, 301, 305, 302,...   [[]]     [663]  [244]   \n",
       "11  [[303, 301, 301, 301, 301, 301, 301, 305, 302,...   [[]]     [678]  [237]   \n",
       "12  [[303, 301, 301, 301, 301, 301, 303, 303, 303,...   [[]]     [476]  [121]   \n",
       "\n",
       "                                              MOVE_TO WEAPON_DEG CHIP_DEG  \\\n",
       "0                                      [486, 10, 499]        [0]    [173]   \n",
       "1                                      [581, 10, 463]        [0]    [173]   \n",
       "2                          [482, 1, 482, 464, 2, 446]       [29]     [16]   \n",
       "3                                                  []       [29]     [17]   \n",
       "4   [428, 1, 428, 446, 1, 446, 428, 1, 428, 446, 1...        [6]     [15]   \n",
       "5                                                  []        [6]     [15]   \n",
       "6   [428, 1, 428, 446, 1, 446, 428, 1, 428, 446, 1...        [2]     [17]   \n",
       "7                                                  []       [29]     [17]   \n",
       "8   [428, 1, 428, 446, 1, 446, 428, 1, 428, 446, 1...        [9]     [14]   \n",
       "9                                                  []        [9]     [14]   \n",
       "10  [428, 1, 428, 446, 1, 446, 428, 1, 428, 446, 1...        [6]     [16]   \n",
       "11                                                 []        [6]     [16]   \n",
       "12  [428, 1, 428, 410, 1, 410, 392, 1, 392, 410, 1...        [5]    [148]   \n",
       "\n",
       "                                                 MAPS  \\\n",
       "0   [486, 503, 520, 502, 484, 466, 483, 465, 482, ...   \n",
       "1   [581, 564, 547, 530, 513, 496, 514, 497, 480, ...   \n",
       "2                                     [482, 464, 446]   \n",
       "3                                                  []   \n",
       "4            [428, 446, 428, 446, 428, 446, 428, 446]   \n",
       "5                                                  []   \n",
       "6            [428, 446, 428, 446, 428, 446, 428, 446]   \n",
       "7                                                  []   \n",
       "8            [428, 446, 428, 446, 428, 446, 428, 446]   \n",
       "9                                                  []   \n",
       "10           [428, 446, 428, 446, 428, 446, 428, 446]   \n",
       "11                                                 []   \n",
       "12  [428, 410, 392, 410, 392, 410, 392, 410, 392, ...   \n",
       "\n",
       "                               WEAPON_ID  \\\n",
       "0                                     []   \n",
       "1                                     []   \n",
       "2                           [41, 41, 41]   \n",
       "3                           [41, 41, 41]   \n",
       "4               [38, 38, 38, 38, 38, 38]   \n",
       "5               [38, 38, 38, 38, 38, 38]   \n",
       "6                               [45, 45]   \n",
       "7                           [41, 41, 41]   \n",
       "8   [38, 38, 38, 38, 38, 38, 38, 38, 38]   \n",
       "9   [38, 38, 38, 38, 38, 38, 38, 38, 38]   \n",
       "10              [38, 38, 38, 38, 38, 38]   \n",
       "11              [38, 38, 38, 38, 38, 38]   \n",
       "12                  [38, 38, 38, 38, 38]   \n",
       "\n",
       "                                    CHIP_ID  ID_GEN  ID_FIGHT  ID_ENTITY  \\\n",
       "0   [14, 14, 96, 96, 19, 20, 20, 3, 21, 21]     243        10         62   \n",
       "1   [14, 14, 96, 96, 19, 20, 20, 3, 21, 21]     243        10         12   \n",
       "2                               [4, 97, 19]     243        10         62   \n",
       "3                                [97, 4, 3]     243        10         12   \n",
       "4                               [97, 2, 18]     243        10         62   \n",
       "5                               [97, 2, 18]     243        10         12   \n",
       "6                                [97, 4, 3]     243        10         62   \n",
       "7                                [97, 4, 3]     243        10         12   \n",
       "8                                   [97, 2]     243        10         62   \n",
       "9                                   [97, 2]     243        10         12   \n",
       "10                               [97, 4, 2]     243        10         62   \n",
       "11                               [97, 4, 2]     243        10         12   \n",
       "12                      [14, 14, 96, 96, 3]     243        10         62   \n",
       "\n",
       "    ID_TURN                                            ACTIONS  \n",
       "0         0  [[1, 4, 4, 1, 4, 4, 1, 1, 4, 2, 1, 4, 4, 1, 4,...  \n",
       "1         0  [[1, 4, 4, 1, 4, 4, 1, 1, 4, 2, 1, 4, 4, 1, 4,...  \n",
       "2         1  [[1, 4, 2, 4, 4, 1, 4, 2, 2, 4, 1, 1, 1, 4, 2,...  \n",
       "3         1  [[2, 1, 4, 2, 2, 4, 4, 1, 4, 2, 2, 4, 1, 1, 1,...  \n",
       "4         2  [[2, 4, 4, 4, 1, 4, 2, 4, 2, 4, 2, 1, 4, 2, 4,...  \n",
       "5         2  [[2, 2, 4, 4, 4, 1, 4, 2, 4, 2, 4, 2, 1, 4, 2,...  \n",
       "6         3  [[2, 2, 4, 4, 1, 4, 2, 2, 1, 4, 2, 2, 1, 1, 4,...  \n",
       "7         3  [[2, 2, 2, 4, 4, 1, 4, 2, 2, 4, 4, 1, 4, 2, 2,...  \n",
       "8         4  [[2, 2, 2, 4, 1, 4, 2, 2, 4, 2, 2, 4, 2, 2, 1,...  \n",
       "9         4  [[2, 2, 2, 4, 4, 1, 4, 2, 2, 4, 2, 2, 4, 2, 2,...  \n",
       "10        5  [[2, 2, 2, 4, 1, 4, 2, 2, 4, 2, 2, 4, 2, 2, 1,...  \n",
       "11        5  [[2, 2, 2, 4, 1, 4, 2, 2, 4, 2, 2, 4, 2, 2, 1,...  \n",
       "12        6  [[2, 2, 2, 4, 1, 4, 2, 2, 4, 2, 2, 4, 2, 2, 1,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(rr.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f11f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
